{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11220481,"sourceType":"datasetVersion","datasetId":7007279},{"sourceId":11220495,"sourceType":"datasetVersion","datasetId":7007286},{"sourceId":230654224,"sourceType":"kernelVersion"},{"sourceId":312775,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":265428,"modelId":286512}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q --upgrade keras-hub\n!pip install -q --upgrade keras  # Upgrade to Keras 3.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-01T03:24:16.366945Z","iopub.execute_input":"2025-04-01T03:24:16.367318Z","iopub.status.idle":"2025-04-01T03:24:23.809238Z","shell.execute_reply.started":"2025-04-01T03:24:16.367292Z","shell.execute_reply":"2025-04-01T03:24:23.808063Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import os\nimport keras_hub\nimport keras\nimport os\nimport re\nimport tensorflow as tf\n\n\nimport tensorflow.data as tf_data\nimport tensorflow.strings as tf_strings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T03:24:51.011596Z","iopub.execute_input":"2025-04-01T03:24:51.012211Z","iopub.status.idle":"2025-04-01T03:24:51.016649Z","shell.execute_reply.started":"2025-04-01T03:24:51.012179Z","shell.execute_reply":"2025-04-01T03:24:51.015636Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Data\nBATCH_SIZE = 64\nSEQ_LEN = 128  # Including BOS and EOS tokens, adjusted from 128 to 129\nVOCAB_SIZE = 20000  # Updated from 5000 to 20000\nMIN_STRING_LEN = 512  # Keeping it as is for now\n\n# Model\nEMBED_DIM = 256  # Increased from 128 for better representation\nFEED_FORWARD_DIM = 1024  # Increased from 128, should be at least 4x of embedding dimension\nNUM_HEADS = 8  # Increased from 4 for better parallelization\nNUM_LAYERS = 4  # Increased from 4 for more depth\n\n# Training\nEPOCHS = 5  # Reduced for quicker initial training\n\n# Inference\nNUM_TOKENS_TO_GENERATE = 80  # Keeping the same\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T03:24:52.805736Z","iopub.execute_input":"2025-04-01T03:24:52.806100Z","iopub.status.idle":"2025-04-01T03:24:52.810302Z","shell.execute_reply.started":"2025-04-01T03:24:52.806072Z","shell.execute_reply":"2025-04-01T03:24:52.809366Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from keras import backend as K\nK.clear_session()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T03:22:39.798923Z","iopub.execute_input":"2025-04-01T03:22:39.799304Z","iopub.status.idle":"2025-04-01T03:22:40.176624Z","shell.execute_reply.started":"2025-04-01T03:22:39.799275Z","shell.execute_reply":"2025-04-01T03:22:40.175673Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import keras\nimport keras_hub\nfrom keras.callbacks import ModelCheckpoint\nimport tensorflow as tf\n\n# Enable MirroredStrategy for using multiple GPUs\nstrategy = tf.distribute.MirroredStrategy()\n\nprint(f\"Number of GPUs: {strategy.num_replicas_in_sync}\")\n\n# Adjusting batch size to account for multi-GPU training\nGLOBAL_BATCH_SIZE = BATCH_SIZE * strategy.num_replicas_in_sync  # Effective batch size\n\n# Use the strategy for building and compiling the model\nwith strategy.scope():\n    # Model Inputs\n    inputs = keras.layers.Input(shape=(None,), dtype=\"int32\")\n    x = keras.layers.Masking(mask_value=0)(inputs)\n\n    # Embedding.\n    embedding_layer = keras_hub.layers.TokenAndPositionEmbedding(\n        vocabulary_size=VOCAB_SIZE,\n        sequence_length=SEQ_LEN,\n        embedding_dim=EMBED_DIM,\n        mask_zero=True,\n    )\n    x = embedding_layer(inputs)\n    # Transformer decoders.\n    for _ in range(NUM_LAYERS):\n        decoder_layer = keras_hub.layers.TransformerDecoder(\n            num_heads=NUM_HEADS,\n            intermediate_dim=FEED_FORWARD_DIM,\n        )\n        x = decoder_layer(x)  # Giving one argument only skips cross-attention.\n    # Output.\n    outputs = keras.layers.Dense(VOCAB_SIZE)(x)\n    model = keras.Model(inputs=inputs, outputs=outputs)\n    loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n    perplexity = keras_hub.metrics.Perplexity(from_logits=True, mask_token_id=0)\n    optimizer = keras.optimizers.Adam(learning_rate=0.0001, clipnorm=1.0)\n    model.compile(optimizer=optimizer, loss=loss_fn, metrics=[perplexity])\n\n    # Model Summary\n    model.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T22:37:31.352982Z","iopub.execute_input":"2025-03-31T22:37:31.353284Z","iopub.status.idle":"2025-03-31T22:37:33.090996Z","shell.execute_reply.started":"2025-03-31T22:37:31.353261Z","shell.execute_reply":"2025-03-31T22:37:33.090325Z"}},"outputs":[{"name":"stdout","text":"Number of GPUs: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ token_and_position_embedding         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │       \u001b[38;5;34m5,152,768\u001b[0m │\n│ (\u001b[38;5;33mTokenAndPositionEmbedding\u001b[0m)          │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ transformer_decoder                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │         \u001b[38;5;34m789,760\u001b[0m │\n│ (\u001b[38;5;33mTransformerDecoder\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ transformer_decoder_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │         \u001b[38;5;34m789,760\u001b[0m │\n│ (\u001b[38;5;33mTransformerDecoder\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ transformer_decoder_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │         \u001b[38;5;34m789,760\u001b[0m │\n│ (\u001b[38;5;33mTransformerDecoder\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ transformer_decoder_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │         \u001b[38;5;34m789,760\u001b[0m │\n│ (\u001b[38;5;33mTransformerDecoder\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20000\u001b[0m)         │       \u001b[38;5;34m5,140,000\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ token_and_position_embedding         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">5,152,768</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionEmbedding</span>)          │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ transformer_decoder                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">789,760</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ transformer_decoder_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">789,760</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ transformer_decoder_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">789,760</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ transformer_decoder_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">789,760</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20000</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">5,140,000</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,451,808\u001b[0m (51.31 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,451,808</span> (51.31 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,451,808\u001b[0m (51.31 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,451,808</span> (51.31 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# Define directory paths for saving datasets\noutput_dir = \"/kaggle/input/processed-wikipedia-dataset/saved_datasets\"\ntrain_dir = os.path.join(output_dir, \"train_ds\")\nval_dir = os.path.join(output_dir, \"val_ds\")\n\n# Reloading train_ds and val_ds\nloaded_train_ds = tf.data.experimental.load(train_dir)\nloaded_val_ds = tf.data.experimental.load(val_dir)\n\nprint(\"Training dataset loaded successfully!\")\nprint(\"Validation dataset loaded successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T22:37:37.984928Z","iopub.execute_input":"2025-03-31T22:37:37.985241Z","iopub.status.idle":"2025-03-31T22:37:38.031667Z","shell.execute_reply.started":"2025-03-31T22:37:37.985213Z","shell.execute_reply":"2025-03-31T22:37:38.030812Z"}},"outputs":[{"name":"stdout","text":"Training dataset loaded successfully!\nValidation dataset loaded successfully!\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"for features, labels in loaded_train_ds.take(3):\n    print(\"Features (Input Tokens):\", features)\n    print(\"Labels (Target Tokens):\", labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T22:37:15.423581Z","iopub.execute_input":"2025-03-31T22:37:15.423907Z","iopub.status.idle":"2025-03-31T22:37:15.525559Z","shell.execute_reply.started":"2025-03-31T22:37:15.423882Z","shell.execute_reply":"2025-03-31T22:37:15.524754Z"}},"outputs":[{"name":"stdout","text":"Features (Input Tokens): tf.Tensor(\n[[    2  1997   134 ...    69   198   392]\n [    2    69 12554 ...  5131  2883 19946]\n [    2    69  6170 ...     0     0     0]\n ...\n [    2  5825    33 ...     0     0     0]\n [    2  3362    78 ...     0     0     0]\n [    2 15311   123 ...     0     0     0]], shape=(64, 128), dtype=int32)\nLabels (Target Tokens): tf.Tensor(\n[[ 1997   134 19953 ...   198   392  1120]\n [   69 12554 16503 ...  2883 19946   135]\n [   69  6170 10860 ...     0     0     0]\n ...\n [ 5825    33   107 ...     0     0     0]\n [ 3362    78  3474 ...     0     0     0]\n [15311   123   386 ...     0     0     0]], shape=(64, 128), dtype=int32)\nFeatures (Input Tokens): tf.Tensor(\n[[    2   135   377 ...     0     0     0]\n [    2  1700 11628 ...     0     0     0]\n [    2   135 10728 ...     0     0     0]\n ...\n [    2 10677  3631 ... 19946  1718   356]\n [    2  1282    10 ...     0     0     0]\n [    2 17046   435 ...   535 19945    33]], shape=(64, 128), dtype=int32)\nLabels (Target Tokens): tf.Tensor(\n[[  135   377  1434 ...     0     0     0]\n [ 1700 11628   626 ...     0     0     0]\n [  135 10728    44 ...     0     0     0]\n ...\n [10677  3631  2945 ...  1718   356  1512]\n [ 1282    10  2036 ...     0     0     0]\n [17046   435   632 ... 19945    33   518]], shape=(64, 128), dtype=int32)\nFeatures (Input Tokens): tf.Tensor(\n[[   2   69 5008 ...    0    0    0]\n [   2  926 1955 ...    0    0    0]\n [   2  135 3208 ...    0    0    0]\n ...\n [   2  874 2287 ...    0    0    0]\n [   2  845  185 ...    0    0    0]\n [   2  682  563 ...    0    0    0]], shape=(64, 128), dtype=int32)\nLabels (Target Tokens): tf.Tensor(\n[[  69 5008 3798 ...    0    0    0]\n [ 926 1955   69 ...    0    0    0]\n [ 135 3208   69 ...    0    0    0]\n ...\n [ 874 2287  185 ...    0    0    0]\n [ 845  185   79 ...    0    0    0]\n [ 682  563  185 ...    0    0    0]], shape=(64, 128), dtype=int32)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"PROTO_FILE = \"/kaggle/input/bpe-tokenizer-200k/tokenizer_bpe.proto\"\ntokenizer = keras_hub.tokenizers.SentencePieceTokenizer(\n    proto=PROTO_FILE,\n    dtype=\"int32\",\n    sequence_length=SEQ_LEN,  # Maintain same sequence length as training\n    add_bos=True,  # Start token is needed to indicate the beginning of the generation\n    add_eos=False  # No end token for generation, only for training\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T03:24:58.325186Z","iopub.execute_input":"2025-04-01T03:24:58.325566Z","iopub.status.idle":"2025-04-01T03:25:00.482095Z","shell.execute_reply.started":"2025-04-01T03:24:58.325514Z","shell.execute_reply":"2025-04-01T03:25:00.481012Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class TopKTextGenerator(keras.callbacks.Callback):\n    \"\"\"A callback to generate text from a trained model using top-k sampling.\"\"\"\n\n    def __init__(self, k, tokenizer, gpt_model):  # Changed model to gpt_model\n        self.sampler = keras_hub.samplers.TopKSampler(k)\n        self.tokenizer = tokenizer\n        self.gpt_model = gpt_model  # Changed attribute name to gpt_model\n\n    def on_epoch_end(self, epoch, logs=None):\n        prompt = tf.constant([\"\"])  # Empty prompt to start generation\n        prompt_tokens = self.tokenizer.tokenize(prompt)\n\n        output_tokens = self.sampler(\n            next=self.next,\n            prompt=prompt_tokens,\n            index=1,\n        )\n        \n        txt = self.tokenizer.detokenize(output_tokens)\n        print(f\"\\nTop-K search generated text after epoch {epoch + 1}: \\n{txt}\\n\")\n\n    def next(self, prompt, cache, index):\n        logits = self.gpt_model(prompt)[:, index - 1, :]  # Using self.gpt_model instead of self.model\n        hidden_states = None  # Not using hidden states for now\n        return logits, hidden_states, cache\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T01:14:16.754542Z","iopub.execute_input":"2025-03-31T01:14:16.754846Z","iopub.status.idle":"2025-03-31T01:14:16.760269Z","shell.execute_reply.started":"2025-03-31T01:14:16.754820Z","shell.execute_reply":"2025-03-31T01:14:16.759379Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Saving model weights if validation perplexity is the best seen so far\ncheckpoint_callback = ModelCheckpoint(\n    \"redblock_gpt_big.keras\",\n    monitor=\"val_perplexity\",\n    save_best_only=True,\n    save_weights_only=False,\n    verbose=1,\n    mode=\"min\"\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T01:14:18.167491Z","iopub.execute_input":"2025-03-31T01:14:18.167785Z","iopub.status.idle":"2025-03-31T01:14:18.171394Z","shell.execute_reply.started":"2025-03-31T01:14:18.167759Z","shell.execute_reply":"2025-03-31T01:14:18.170550Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"text_generation_callback = TopKTextGenerator(k=10, tokenizer=tokenizer, gpt_model=model)\n\nmodel.fit(\n    loaded_train_ds,\n    validation_data=loaded_val_ds,\n    epochs=EPOCHS,\n    callbacks=[text_generation_callback, checkpoint_callback]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T01:14:19.014114Z","iopub.execute_input":"2025-03-31T01:14:19.014325Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Prompt tokens:\", prompt_tokens)\nlogits, _, _ = next(prompt_tokens, None, 1)\nprint(\"Logits shape:\", logits.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T06:00:56.627920Z","iopub.execute_input":"2025-03-31T06:00:56.628230Z","iopub.status.idle":"2025-03-31T06:00:56.707602Z","shell.execute_reply.started":"2025-03-31T06:00:56.628201Z","shell.execute_reply":"2025-03-31T06:00:56.706791Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save(\"redblock_pretrained_gpt_epoch_5.keras\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"loaded_model = keras.saving.load_model(\"/kaggle/input/redblock_trained_gpt/keras/default/1/redblock_gpt_big (5).keras\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T03:25:07.957702Z","iopub.execute_input":"2025-04-01T03:25:07.958009Z","iopub.status.idle":"2025-04-01T03:25:12.031708Z","shell.execute_reply.started":"2025-04-01T03:25:07.957988Z","shell.execute_reply":"2025-04-01T03:25:12.031011Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"loaded_model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T03:25:12.032960Z","iopub.execute_input":"2025-04-01T03:25:12.033231Z","iopub.status.idle":"2025-04-01T03:25:12.057416Z","shell.execute_reply.started":"2025-04-01T03:25:12.033208Z","shell.execute_reply":"2025-04-01T03:25:12.056639Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ token_and_position_embedding_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │       \u001b[38;5;34m5,152,768\u001b[0m │\n│ (\u001b[38;5;33mTokenAndPositionEmbedding\u001b[0m)          │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ transformer_decoder_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │         \u001b[38;5;34m789,760\u001b[0m │\n│ (\u001b[38;5;33mTransformerDecoder\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ transformer_decoder_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │         \u001b[38;5;34m789,760\u001b[0m │\n│ (\u001b[38;5;33mTransformerDecoder\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ transformer_decoder_6                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │         \u001b[38;5;34m789,760\u001b[0m │\n│ (\u001b[38;5;33mTransformerDecoder\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ transformer_decoder_7                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │         \u001b[38;5;34m789,760\u001b[0m │\n│ (\u001b[38;5;33mTransformerDecoder\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20000\u001b[0m)         │       \u001b[38;5;34m5,140,000\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ token_and_position_embedding_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">5,152,768</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionEmbedding</span>)          │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ transformer_decoder_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">789,760</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ transformer_decoder_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">789,760</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ transformer_decoder_6                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">789,760</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ transformer_decoder_7                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">789,760</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20000</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">5,140,000</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m40,355,426\u001b[0m (153.94 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,355,426</span> (153.94 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,451,808\u001b[0m (51.31 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,451,808</span> (51.31 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m26,903,618\u001b[0m (102.63 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,903,618</span> (102.63 MB)\n</pre>\n"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# The \"packer\" layers adds the [BOS] token for us.\nprompt_tokens =tokenizer.tokenize([\"\"])\nprompt_tokens\n\ndef next(prompt, cache, index):\n    logits = loaded_model(prompt)[:, index - 1, :]\n    # Ignore hidden states for now; only needed for contrastive search.\n    hidden_states = None\n    return logits, hidden_states, cache\nprompt_length = tf.math.count_nonzero(prompt_tokens, axis=-1)[0].numpy()\n\nsampler = keras_hub.samplers.TopPSampler(p=0.5)\noutput_tokens = sampler(\n    next=next,\n    prompt=prompt_tokens,\n    index=prompt_length,\n)\ntxt = tokenizer.detokenize(output_tokens)\nprint(f\"Top-P search generated text: \\n{txt}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T23:47:37.379851Z","iopub.execute_input":"2025-03-31T23:47:37.380133Z","iopub.status.idle":"2025-03-31T23:47:52.061113Z","shell.execute_reply.started":"2025-03-31T23:47:37.380113Z","shell.execute_reply":"2025-03-31T23:47:52.060198Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:939: UserWarning: Layer 'position_embedding' (of type PositionEmbedding) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:939: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:939: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:939: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Top-P search generated text: \n['As a teenager, he had two sons, James and Henry. His father, John and William, were a real-life father, John and his mother, and their mother, Ellen, are a son of Thomas, the younger sister of John, John and their daughter, William, and a sister, John. of the family are the only daughter of Edward, and their mother was born in an early age. Thomas is the only child, and she is a member of the House of Fife. of the family and the children were raised in the hands of the family. of the siblings were of']\n\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"def evaluate_model(model, eval_dataset):\n    # Define the metrics to use in evaluation\n    perplexity = keras_hub.metrics.Perplexity(from_logits=True, mask_token_id=0) # Assuming 0 is the padding token\n\n    # Run the evaluation\n    results = model.evaluate(eval_dataset, \n                             batch_size=64,  # Adjust this as needed\n                             verbose=1, \n                             )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T22:38:01.602657Z","iopub.execute_input":"2025-03-31T22:38:01.602951Z","iopub.status.idle":"2025-03-31T22:38:01.607161Z","shell.execute_reply.started":"2025-03-31T22:38:01.602928Z","shell.execute_reply":"2025-03-31T22:38:01.606208Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"evaluate_model(loaded_model, loaded_val_ds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T22:38:02.332892Z","iopub.execute_input":"2025-03-31T22:38:02.333170Z","iopub.status.idle":"2025-03-31T22:43:03.414314Z","shell.execute_reply.started":"2025-03-31T22:38:02.333150Z","shell.execute_reply":"2025-03-31T22:43:03.413654Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:939: UserWarning: Layer 'position_embedding' (of type PositionEmbedding) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:939: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:939: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:939: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2174/2174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 137ms/step - loss: 4.1417 - perplexity: 66.0906\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"!pip install bert_score sentence_transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T03:25:27.829106Z","iopub.execute_input":"2025-04-01T03:25:27.829448Z","iopub.status.idle":"2025-04-01T03:25:31.923144Z","shell.execute_reply.started":"2025-04-01T03:25:27.829418Z","shell.execute_reply":"2025-04-01T03:25:31.921923Z"}},"outputs":[{"name":"stdout","text":"Collecting bert_score\n  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\nRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.5.1+cu121)\nRequirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.2.3)\nRequirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.47.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert_score) (1.26.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.32.3)\nRequirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.67.1)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert_score) (3.7.5)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert_score) (24.2)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.13.1)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.29.0)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (11.0.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.17.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.12.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2025.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert_score) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.4.5)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.4.7)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (3.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2025.1.31)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert_score) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->bert_score) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->bert_score) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->bert_score) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->bert_score) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->bert_score) (2024.2.0)\nDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: bert_score\nSuccessfully installed bert_score-0.3.13\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import torch\nfrom transformers import BertModel, BertTokenizer\nfrom bert_score import score\nfrom sentence_transformers import SentenceTransformer, util\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T03:25:34.695794Z","iopub.execute_input":"2025-04-01T03:25:34.696173Z","iopub.status.idle":"2025-04-01T03:25:42.261826Z","shell.execute_reply.started":"2025-04-01T03:25:34.696142Z","shell.execute_reply":"2025-04-01T03:25:42.261115Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\nbert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\nsentence_transformer = SentenceTransformer('all-mpnet-base-v2')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T03:25:44.252630Z","iopub.execute_input":"2025-04-01T03:25:44.253272Z","iopub.status.idle":"2025-04-01T03:25:52.043740Z","shell.execute_reply.started":"2025-04-01T03:25:44.253242Z","shell.execute_reply":"2025-04-01T03:25:52.042647Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"487bf6ed680f49c89a714fe1b5067a0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e874df7de35443e8b7edb9ef9a54dbd3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7b1de41cec84ec1b6035198bbc709d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9447670745564a75802bca4c1dabd15d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3cd61565798549ef9db052ff6b42e42e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1943ecdbdac74091b5dff63170338870"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7aae111aa8d4a9bbdd6cd04d7b5f786"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"895edb0582df479e852a3efe03d928f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c119af37e2c4754b5881b0a7b083d24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7af50a3197a54ea09fb4cddd1025383d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c0dfdd418484d65bb26d226024c28b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e49141095e848619c3e13cabad633a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2143974e48a9415eb1b1fe8f09c42403"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed311a756c2c43288b987de1d986d17d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07b24e317223479a829a070b8e798431"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b9a8189b3cd4195918ea368e37ad7d0"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"def calculate_bert_score(text: str) -> float:\n    sentences = text.strip().split(\".\")\n    if len(sentences) < 2:\n        return 0.0  # Not enough sentences to compare\n\n    P, R, F1 = score([sentences[1]], [sentences[0]], model_type=\"bert-base-uncased\", lang=\"en\")\n    return F1.mean().item()\n\ndef calculate_sentence_similarity(text: str) -> float:\n    sentences = text.strip().split(\".\")\n    sentences = [s.strip() for s in sentences if s.strip()]\n\n    if len(sentences) < 2:\n        return 0.0  # Not enough sentences to compare\n\n    embeddings = sentence_transformer.encode(sentences)\n    similarities = []\n    for i in range(1, len(embeddings)):\n        sim = util.cos_sim(embeddings[i-1], embeddings[i])\n        similarities.append(sim.item())\n\n    return np.mean(similarities) if similarities else 0.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T03:25:52.045003Z","iopub.execute_input":"2025-04-01T03:25:52.045241Z","iopub.status.idle":"2025-04-01T03:25:52.051905Z","shell.execute_reply.started":"2025-04-01T03:25:52.045222Z","shell.execute_reply":"2025-04-01T03:25:52.050990Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"import numpy as np\nfrom tqdm import tqdm\nsampler = keras_hub.samplers.TopPSampler(p=0.5)\ndef generate_and_evaluate(n=5):\n    bert_scores = []\n    sentence_similarities = []\n    generated_texts = []\n    \n    for i in tqdm(range(n), desc=\"Generating Texts\"):\n        output_tokens = sampler(\n            next=next,\n            prompt=prompt_tokens,\n            index=prompt_length,\n        )\n        \n        txt = tokenizer.detokenize(output_tokens)\n        generated_texts.append(txt[0])\n        \n        bert_score = calculate_bert_score(txt[0])\n        sentence_similarity = calculate_sentence_similarity(txt[0])\n        \n        bert_scores.append(bert_score)\n        sentence_similarities.append(sentence_similarity)\n        \n        print(f\"Generated Text {i+1}: {txt[0]}\")\n        print(f\"BERTScore F1: {bert_score}\")\n        print(f\"Sentence Similarity: {sentence_similarity}\\n\")\n    \n    avg_bert_score = np.mean(bert_scores)\n    avg_sentence_similarity = np.mean(sentence_similarities)\n    \n    return avg_bert_score, avg_sentence_similarity, generated_texts\n\n# Run the loop 100 times\navg_bert_score, avg_sentence_similarity, generated_texts = generate_and_evaluate(3)\n\n# Print results\nprint(f\"Average BERTScore F1: {avg_bert_score}\")\nprint(f\"Average Sentence Similarity: {avg_sentence_similarity}\")\n\n# Store generated texts in a file for reference\nwith open(\"generated_texts.txt\", \"w\") as f:\n    for text in generated_texts:\n        f.write(text + \"\\n\\n\")\n\nprint(\"Generated texts saved to generated_texts.txt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T03:35:00.575789Z","iopub.execute_input":"2025-04-01T03:35:00.576142Z","iopub.status.idle":"2025-04-01T03:35:36.583580Z","shell.execute_reply.started":"2025-04-01T03:35:00.576118Z","shell.execute_reply":"2025-04-01T03:35:36.582609Z"}},"outputs":[{"name":"stderr","text":"Generating Texts:   0%|          | 0/3 [00:00<?, ?it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64f76bab9ab14d02922a4883957d19d3"}},"metadata":{}},{"name":"stderr","text":"Generating Texts:  33%|███▎      | 1/3 [00:12<00:24, 12.38s/it]","output_type":"stream"},{"name":"stdout","text":"Generated Text 1: On February 15, 2015, Shirez was appointed head coach of the Miami Marlins. He was replaced by fellow midfielders Chris Morrison. members of the Philadelphia Eagles have a long time of sponsorship. of the coaching staff, his coach, Mike McCain, was head coach of the Florida Marlins. was a starter in the senior season, and was also a defensive midfielder. of the roster included former Denver All-American and former Houston Blue Ribbon. later played for the Houston Marlins, a forward and former Texas Rangers. of the season, he was a member\nBERTScore F1: 0.3561050593852997\nSentence Similarity: 0.26706443833453314\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4f9f9624ea8460c9d01b847dae7400d"}},"metadata":{}},{"name":"stderr","text":"Generating Texts:  67%|██████▋   | 2/3 [00:23<00:11, 11.92s/it]","output_type":"stream"},{"name":"stdout","text":"Generated Text 2: The book received mixed reviews. The reviewer praised the story's style, \"homething about the heart, I'm looking at a bit of as it was an excellent, intimate character, and the creativity of it, it's very much more good, and less than a simple thing.\" Similarly, in The Wizard of Oz, the writer noted the writer, \"Areus, in an aforementioned account of this story, has been compared to a romance, and the \"Digly, I'm anaite, and his ostensibly ambitious, and yet another,\nBERTScore F1: 0.41395023465156555\nSentence Similarity: 0.4422805905342102\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71e7ac3078434345b63ce5ba12dd2fec"}},"metadata":{}},{"name":"stderr","text":"Generating Texts: 100%|██████████| 3/3 [00:35<00:00, 12.00s/it]","output_type":"stream"},{"name":"stdout","text":"Generated Text 3: The highest peaks of the volcano are in the Pacific Ocean. The highest peak is , which is at sea level. The mountain ranges are located on the coast of Santa Cruz Island, and are the largest volcanoes in the island. of the same time, the mountain is located in the northern part of the island. of the mountain range, the western coast of the island is named for the northern part of the island. of the last volcano, the city of the island is named after a legendary volcano, a city that is named after the present-day city of Santa Cruz, where the city is known\nBERTScore F1: 0.6094847917556763\nSentence Similarity: 0.5191057324409485\n\nAverage BERTScore F1: 0.4598466952641805\nAverage Sentence Similarity: 0.4094835871032306\nGenerated texts saved to generated_texts.txt\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"import numpy as np\nfrom tqdm import tqdm\nsampler = keras_hub.samplers.TopKSampler(k=10)\ndef generate_and_evaluate(n=5):\n    bert_scores = []\n    sentence_similarities = []\n    generated_texts = []\n    \n    for i in tqdm(range(n), desc=\"Generating Texts\"):\n        output_tokens = sampler(\n            next=next,\n            prompt=prompt_tokens,\n            index=prompt_length,\n        )\n        \n        txt = tokenizer.detokenize(output_tokens)\n        generated_texts.append(txt[0])\n        \n        bert_score = calculate_bert_score(txt[0])\n        sentence_similarity = calculate_sentence_similarity(txt[0])\n        \n        bert_scores.append(bert_score)\n        sentence_similarities.append(sentence_similarity)\n        \n        print(f\"Generated Text {i+1}: {txt[0]}\")\n        print(f\"BERTScore F1: {bert_score}\")\n        print(f\"Sentence Similarity: {sentence_similarity}\\n\")\n    \n    avg_bert_score = np.mean(bert_scores)\n    avg_sentence_similarity = np.mean(sentence_similarities)\n    \n    return avg_bert_score, avg_sentence_similarity, generated_texts\n\n# Run the loop 100 times\navg_bert_score, avg_sentence_similarity, generated_texts = generate_and_evaluate(3)\n\n# Print results\nprint(f\"Average BERTScore F1: {avg_bert_score}\")\nprint(f\"Average Sentence Similarity: {avg_sentence_similarity}\")\n\n# Store generated texts in a file for reference\nwith open(\"generated_texts.txt\", \"w\") as f:\n    for text in generated_texts:\n        f.write(text + \"\\n\\n\")\n\nprint(\"Generated texts saved to generated_texts.txt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T03:38:49.264937Z","iopub.execute_input":"2025-04-01T03:38:49.265266Z","iopub.status.idle":"2025-04-01T03:39:24.541115Z","shell.execute_reply.started":"2025-04-01T03:38:49.265243Z","shell.execute_reply":"2025-04-01T03:39:24.540030Z"}},"outputs":[{"name":"stderr","text":"Generating Texts:   0%|          | 0/3 [00:00<?, ?it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8c631d3c00e455f98aa01fbcf5e434f"}},"metadata":{}},{"name":"stderr","text":"Generating Texts:  33%|███▎      | 1/3 [00:11<00:22, 11.36s/it]","output_type":"stream"},{"name":"stdout","text":"Generated Text 1: In August 2015, he was appointed to the position of the new president in a position. In January 2016, he joined the new board of directors and vice president and was the president of the board of the new board. of staff in the board, a board member was appointed to the chairman of the board in August. members of the board voted to have two members, with the president, and two other members, and the chairman of the board are elected to the President.man, who has been elected to the board of directors, was elected a member of the board. of staff members are eligible to\nBERTScore F1: 0.6620436310768127\nSentence Similarity: 0.5664778828620911\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14ab53653e024f32a6f993a0c9e3c1d0"}},"metadata":{}},{"name":"stderr","text":"Generating Texts:  67%|██████▋   | 2/3 [00:22<00:11, 11.35s/it]","output_type":"stream"},{"name":"stdout","text":"Generated Text 2: The first three teams of the league began in June, the fifth and final team in the league were seeded by the second round. The teams were drawn from the two teams, and each team was divided into six teams and one teams. The first team of the team was the first team from the first division. The team finished second place in the season and the second place overall by the second round.ps by then began the season with a team of six teams, the second-tier team from the second round, and the team was eliminated in the second round. The team finished third place in the first round.\nBERTScore F1: 0.5240020751953125\nSentence Similarity: 0.6385317921638489\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8191228f67514724b1138834c447cbb0"}},"metadata":{}},{"name":"stderr","text":"Generating Texts: 100%|██████████| 3/3 [00:35<00:00, 11.75s/it]","output_type":"stream"},{"name":"stdout","text":"Generated Text 3: As of the census of 2000, there were 4,312 people, 8,616 households, and 1,938 families residing in the city. In 2000, there were 11,011 people, 2,415 households, and 4,522 families residing in the city. The population density was 3.0 people per square mile in the city's history.-division of the city of Los Angeles County had 3,5115 households, and 1,611 housing units, as of that year and 1,7159 residents. In the 2010 Census, 2,071 were owner-occupied. In 2013, it was the largest village in\nBERTScore F1: 0.8554472923278809\nSentence Similarity: 0.4457216014464696\n\nAverage BERTScore F1: 0.6804976662000021\nAverage Sentence Similarity: 0.5502437588241366\nGenerated texts saved to generated_texts.txt\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}