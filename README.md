# Mini-LLM-from-Scratch
This repository contains the code and resources for training a minimal-size language model from scratch using the Wikipedia dataset. The model is based on a GPT-style architecture and employs a Causal Language Modeling (CLM) training strategy.
